{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c8df3ef",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409c8b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import relu,linear,sigmoid\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd8038f",
   "metadata": {},
   "source": [
    "#### Read the Data\n",
    "\n",
    "The data being used here can be found from kaagle here: https://www.kaggle.com/datasets/dhanushnarayananr/credit-card-fraud?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fed5a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./card_transdata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6357bd",
   "metadata": {},
   "source": [
    "Run the code below to see examples of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993f43f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343146ce",
   "metadata": {},
   "source": [
    "#### Clean the Data\n",
    "\n",
    "The data needs to be cleaned of any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aefbdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43796c83",
   "metadata": {},
   "source": [
    "#### Split the Data\n",
    "\n",
    "We will split the data into two sets. The training set will have 70% of the data, and the validation set will have the other 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25d1275",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_df.drop(columns=['fraud'])\n",
    "y = cleaned_df['fraud']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0403c6ba",
   "metadata": {},
   "source": [
    "#### Model Initialization\n",
    "\n",
    "The model will use ReLU activation for it's layers until the output layer where we will use sigmoid.\n",
    "\n",
    "The model will be compiled using the Adam optimizer, and since we only have 2 groups to classify data into, we will use Binary CrossEntropy for the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238c256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(7,)),  \n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0e1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d8db48",
   "metadata": {},
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8541a7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cf76cb",
   "metadata": {},
   "source": [
    "#### Plot loss history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4f8d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9743ef1f",
   "metadata": {},
   "source": [
    "#### Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d782fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "predictions = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eb81bf",
   "metadata": {},
   "source": [
    "#### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bff8173",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ccf_model_one.keras\") #you can edit the string here to change the name you want to save the model with\n",
    "                                  #Make sure to keep the .keras to save the model as the proper file type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a14251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
